{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "rankings = pd.read_csv('fifa_ranking.csv')\n",
    "rankings = rankings.loc[:,['rank', 'country_full', 'country_abrv', 'cur_year_avg_weighted', 'rank_date', \n",
    "                           'two_year_ago_weighted', 'three_year_ago_weighted']]\n",
    "rankings = rankings.replace({\"IR Iran\": \"Iran\"})\n",
    "rankings['weighted_points'] =  rankings['cur_year_avg_weighted'] + rankings['two_year_ago_weighted'] + rankings['three_year_ago_weighted']\n",
    "rankings['rank_date'] = pd.to_datetime(rankings['rank_date'])\n",
    "\n",
    "matches = pd.read_csv('results.csv')\n",
    "matches =  matches.replace({'Germany DR': 'Germany', 'China': 'China PR'})\n",
    "matches['date'] = pd.to_datetime(matches['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I want to have the ranks for every day \n",
    "rankings = rankings.set_index(['rank_date']).groupby(['country_full'], group_keys=False).resample('D').first().fillna(method='ffill').reset_index()\n",
    "\n",
    "# join the ranks\n",
    "matches = matches.merge(rankings, \n",
    "                        left_on=['date', 'home_team'], \n",
    "                        right_on=['rank_date', 'country_full'])\n",
    "matches = matches.merge(rankings, \n",
    "                        left_on=['date', 'away_team'], \n",
    "                        right_on=['rank_date', 'country_full'], \n",
    "                        suffixes=('_home', '_away'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature generation\n",
    "matches['rank_difference'] = matches['rank_home'] - matches['rank_away']\n",
    "matches['average_rank'] = (matches['rank_home'] + matches['rank_away'])/2\n",
    "matches['point_difference'] = matches['weighted_points_home'] - matches['weighted_points_away']\n",
    "matches['score_difference'] = matches['home_score'] - matches['away_score']\n",
    "matches['is_won'] = matches['score_difference'] > 0 # take draw as lost\n",
    "#matches.loc[matches['score_difference'] > 0, 'is_won'] = 'True' \n",
    "#matches.loc[matches['score_difference'] < 0, 'is_won'] = 'False'  \n",
    "#matches.loc[matches['score_difference'] == 0, 'is_won'] = 'Draw'  \n",
    "matches['is_stake'] = matches['tournament'] != 'Friendly'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#matches = matches.set_index(['date'])\n",
    "match = matches[['home_team','away_team','tournament','average_rank', 'rank_difference', 'point_difference','is_stake','is_won']]\n",
    "\n",
    "matches1 = matches[['home_team','away_team','tournament','average_rank', 'rank_difference', 'point_difference','is_stake','home_score']]\n",
    "matches2 = matches[['home_team','away_team','tournament','average_rank', 'rank_difference', 'point_difference','is_stake','away_score']]\n",
    "\n",
    "#matches1 = matches[['home_team','home_score','away_team','away_score','tournament','average_rank', 'rank_difference', 'point_difference','is_stake']]\n",
    "#matches2 = matches[['home_team','home_score','away_team','away_score','tournament','average_rank', 'rank_difference', 'point_difference','is_stake']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>home_team</th>\n",
       "      <th>away_team</th>\n",
       "      <th>tournament</th>\n",
       "      <th>average_rank</th>\n",
       "      <th>rank_difference</th>\n",
       "      <th>point_difference</th>\n",
       "      <th>is_stake</th>\n",
       "      <th>is_won</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bolivia</td>\n",
       "      <td>Uruguay</td>\n",
       "      <td>FIFA World Cup qualification</td>\n",
       "      <td>40.5</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Brazil</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>Friendly</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ecuador</td>\n",
       "      <td>Venezuela</td>\n",
       "      <td>FIFA World Cup qualification</td>\n",
       "      <td>64.5</td>\n",
       "      <td>-59.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Guinea</td>\n",
       "      <td>Sierra Leone</td>\n",
       "      <td>Friendly</td>\n",
       "      <td>75.5</td>\n",
       "      <td>-21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Paraguay</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>FIFA World Cup qualification</td>\n",
       "      <td>36.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  home_team     away_team                    tournament  average_rank  \\\n",
       "0   Bolivia       Uruguay  FIFA World Cup qualification          40.5   \n",
       "1    Brazil        Mexico                      Friendly          11.0   \n",
       "2   Ecuador     Venezuela  FIFA World Cup qualification          64.5   \n",
       "3    Guinea  Sierra Leone                      Friendly          75.5   \n",
       "4  Paraguay     Argentina  FIFA World Cup qualification          36.0   \n",
       "\n",
       "   rank_difference  point_difference  is_stake  is_won  \n",
       "0             37.0               0.0      True    True  \n",
       "1             -6.0               0.0     False   False  \n",
       "2            -59.0               0.0      True    True  \n",
       "3            -21.0               0.0     False    True  \n",
       "4             62.0               0.0      True   False  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrics= [[1150  715]\n",
      " [ 707  978]]\n",
      "  \n",
      "accuracy= 59.943661971830984\n",
      "Best score is 0.6770422535211267\n",
      "Tuned GRID SEARCH Tree Parameters: {'max_depth': 4}\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn import ensemble\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, roc_auc_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from scipy.stats import randint\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "labelencoder = LabelEncoder()\n",
    "\n",
    "X, y = match.loc[:,['home_team', 'away_team','tournament', 'average_rank', 'rank_difference','point_difference', 'is_stake']], matches['is_won']\n",
    "\n",
    "\n",
    "X['home_team'] = labelencoder.fit_transform(X['home_team'])\n",
    "X['away_team'] = labelencoder.fit_transform(X['away_team'])\n",
    "X['tournament'] = labelencoder.fit_transform(X['tournament'])\n",
    "X['is_stake'] = labelencoder.fit_transform(X['is_stake'])\n",
    "y = labelencoder.fit_transform(y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Fitting Decision Tree Classification to the Training set\n",
    "param_dist = {\"max_depth\": [3, 100],\n",
    "              \"max_features\": randint(3,7),\n",
    "              \"min_samples_leaf\": randint(1, 9),\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = DecisionTreeClassifier()\n",
    "\n",
    "model.fit(X_train,y_train)\n",
    "pred = model.predict(X_test)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, pred)\n",
    "\n",
    "#accuracy\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "accuracy = accuracy_score(y_test,pred)\n",
    "print(\"confusion matrics=\",cm)\n",
    "print(\"  \")\n",
    "print(\"accuracy=\",accuracy*100)\n",
    "\n",
    "param_grid = {'max_depth': np.arange(3, 10)}\n",
    "\n",
    "tree_cv = GridSearchCV(model, param_grid)\n",
    "tree_cv.fit(X_train,y_train)\n",
    "\n",
    "tree_preds = tree_cv.predict_proba(X_test)[:, 1]\n",
    "print(\"Best score is {}\".format(tree_cv.best_score_))\n",
    "print(\"Tuned GRID SEARCH Tree Parameters: {}\".format(tree_cv.best_params_))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  \n",
      "accuracy= 27.267605633802816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abuba8/.local/lib/python3.8/site-packages/sklearn/model_selection/_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score is 0.331830985915493\n",
      "Tuned GRID SEARCH Tree Parameters: {'max_depth': 4}\n"
     ]
    }
   ],
   "source": [
    "X1, y1 = matches1.loc[:,['home_team', 'away_team','tournament', 'average_rank', 'rank_difference','point_difference', 'is_stake']], matches['home_score']\n",
    "\n",
    "X1['home_team'] = labelencoder.fit_transform(X1['home_team'])\n",
    "X1['away_team'] = labelencoder.fit_transform(X1['away_team'])\n",
    "X1['tournament'] = labelencoder.fit_transform(X1['tournament'])\n",
    "X1['is_stake'] = labelencoder.fit_transform(X1['is_stake'])\n",
    "\n",
    "y1 = labelencoder.fit_transform(y1)\n",
    "\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(\n",
    "    X1, y1, test_size=0.2, random_state=42)\n",
    "\n",
    "model1 = DecisionTreeClassifier()\n",
    "\n",
    "model1.fit(X_train1,y_train1)\n",
    "pred1 = model1.predict(X_test1)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm1 = confusion_matrix(y_test1, pred1)\n",
    "\n",
    "#accuracy\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "accuracy1 = accuracy_score(y_test1,pred1)\n",
    "print(\"  \")\n",
    "print(\"accuracy=\",accuracy1*100)\n",
    "\n",
    "tree_cv1 = GridSearchCV(model1, param_grid)\n",
    "tree_cv1.fit(X_train1,y_train1)\n",
    "\n",
    "tree_preds1 = tree_cv1.predict_proba(X_test1)[:, 1]\n",
    "print(\"Best score is {}\".format(tree_cv1.best_score_))\n",
    "print(\"Tuned GRID SEARCH Tree Parameters: {}\".format(tree_cv1.best_params_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  \n",
      "accuracy= 32.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abuba8/.local/lib/python3.8/site-packages/sklearn/model_selection/_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score is 0.4235915492957746\n",
      "Tuned GRID SEARCH Tree Parameters: {'max_depth': 3}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "X2, y2 = matches2.loc[:,['home_team', 'away_team','tournament', 'average_rank', 'rank_difference','point_difference', 'is_stake']], matches['away_score']\n",
    "\n",
    "\n",
    "\n",
    "X2['home_team'] = labelencoder.fit_transform(X2['home_team'])\n",
    "X2['away_team'] = labelencoder.fit_transform(X2['away_team'])\n",
    "X2['tournament'] = labelencoder.fit_transform(X2['tournament'])\n",
    "X2['is_stake'] = labelencoder.fit_transform(X2['is_stake'])\n",
    "y2 = labelencoder.fit_transform(y2)\n",
    "\n",
    "\n",
    "\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(\n",
    "    X2, y2, test_size=0.2, random_state=42)\n",
    "    \n",
    "\n",
    "\n",
    "model2 = DecisionTreeClassifier()\n",
    "\n",
    "model2.fit(X_train2,y_train2)\n",
    "pred2 = model2.predict(X_test2)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm2 = confusion_matrix(y_test2, pred2)\n",
    "\n",
    "#accuracy\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "accuracy2 = accuracy_score(y_test2,pred2)\n",
    "print(\"  \")\n",
    "print(\"accuracy=\",accuracy2*100)\n",
    "\n",
    "tree_cv2 = GridSearchCV(model2, param_grid)\n",
    "tree_cv2.fit(X_train2,y_train2)\n",
    "tree_preds2 = tree_cv2.predict_proba(X_test2)[:, 1]\n",
    "print(\"Best score is {}\".format(tree_cv2.best_score_))\n",
    "print(\"Tuned GRID SEARCH Tree Parameters: {}\".format(tree_cv2.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logisitic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       average_rank  rank_difference  point_difference  is_stake\n",
      "476            74.0             10.0              0.00      True\n",
      "6959          165.0             32.0              0.00      True\n",
      "13005         123.0             18.0           -138.76      True\n",
      "8466           24.5            -45.0              0.00     False\n",
      "15568          75.0             28.0           -172.41      True\n",
      "[[0.5976807 0.4023193]]\n",
      "confusion matrics= [[1277  588]\n",
      " [ 570 1115]]\n",
      "  \n",
      "accuracy= 67.38028169014085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abuba8/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn import ensemble\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, roc_auc_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "X3, y3 = matches.loc[:,['average_rank', 'rank_difference', 'point_difference', 'is_stake']], matches['is_won']\n",
    "\n",
    "#labelencoder.fit(X3)\n",
    "\n",
    "\n",
    "X_train3, X_test3, y_train3, y_test3 = train_test_split(\n",
    "    X3, y3, test_size=0.2, random_state=42)\n",
    "\n",
    "logreg = linear_model.LogisticRegression(C=1e-5)\n",
    "features = PolynomialFeatures(degree=2)\n",
    "model3 = Pipeline([\n",
    "    ('polynomial_features', features),\n",
    "    ('logistic_regression', logreg)\n",
    "])\n",
    "model3 = model3.fit(X_train3, y_train3)\n",
    "\n",
    "pred3 = model3.predict(X_test3)\n",
    "home_win = model3.predict_proba([[74.0,10.0,0.00,True]])\n",
    "\n",
    "print(X_test3.head())\n",
    "print(home_win)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm3 = confusion_matrix(y_test3, pred3)\n",
    "\n",
    "#accuracy\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "accuracy3 = accuracy_score(y_test3,pred3)\n",
    "print(\"confusion matrics=\",cm3)\n",
    "print(\"  \")\n",
    "print(\"accuracy=\",accuracy3*100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         rank_date   rank    country_full country_abrv  cur_year_avg_weighted  \\\n",
      "5622    2018-06-07  145.0     Afghanistan          AFG                 112.98   \n",
      "14692   2018-06-07   58.0         Albania          ALB                 233.86   \n",
      "23762   2018-06-07   66.0         Algeria          ALG                 163.41   \n",
      "30932   2018-06-07  192.0  American Samoa          ASA                   0.00   \n",
      "38802   2018-06-07  130.0         Andorra          AND                 189.89   \n",
      "...            ...    ...             ...          ...                    ...   \n",
      "1788692 2018-06-07  102.0         Vietnam          VIE                 222.70   \n",
      "1797762 2018-06-07   18.0           Wales          WAL                 335.47   \n",
      "1806832 2018-06-07  133.0           Yemen          YEM                 113.42   \n",
      "1821587 2018-06-07   76.0          Zambia          ZAM                 236.14   \n",
      "1830657 2018-06-07  118.0        Zimbabwe          ZIM                 133.45   \n",
      "\n",
      "         two_year_ago_weighted  three_year_ago_weighted  weighted_points  \n",
      "5622                     31.69                     6.80           151.47  \n",
      "14692                    66.85                   121.05           421.76  \n",
      "23762                    91.40                   101.63           356.44  \n",
      "30932                    38.25                     0.00            38.25  \n",
      "38802                     2.21                     0.00           192.10  \n",
      "...                        ...                      ...              ...  \n",
      "1788692                  47.52                    16.50           286.72  \n",
      "1797762                 107.98                   137.41           580.86  \n",
      "1806832                  21.61                    17.81           152.84  \n",
      "1821587                  56.02                    59.46           351.62  \n",
      "1830657                  69.62                    12.75           215.82  \n",
      "\n",
      "[211 rows x 8 columns]\n",
      "Index(['rank_date', 'rank', 'country_full', 'country_abrv',\n",
      "       'cur_year_avg_weighted', 'two_year_ago_weighted',\n",
      "       'three_year_ago_weighted', 'weighted_points'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# let's define the rankings at the time of the World Cup\n",
    "last_rank = rankings.loc[(rankings['rank_date'] == rankings['rank_date'].max()) & \n",
    "                                    rankings['country_full']]\n",
    "print(last_rank)\n",
    "last_rank.to_csv('file1.csv') \n",
    "print(rankings.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        rank_date   rank country_full country_abrv  cur_year_avg_weighted  \\\n",
      "5622   2018-06-07  145.0  Afghanistan          AFG                 112.98   \n",
      "619586 2018-06-07    7.0       France          FRA                 520.12   \n",
      "\n",
      "        two_year_ago_weighted  three_year_ago_weighted  weighted_points  \n",
      "5622                    31.69                     6.80           151.47  \n",
      "619586                 118.09                   131.54           769.75  \n"
     ]
    }
   ],
   "source": [
    "x=\"Afghanistan\"\n",
    "y=\"France\"\n",
    "home = last_rank.loc[last_rank['country_full'] == x]\n",
    "away = last_rank.loc[last_rank['country_full'] == y]\n",
    "\n",
    "frames = [home, away]\n",
    "result = pd.concat(frames)\n",
    "\n",
    "print(result)\n",
    "row = pd.DataFrame(np.array([[np.nan, np.nan, np.nan, True]]), columns=X_test3.columns)\n",
    "home_rank = result['rank'].iloc[0]\n",
    "home_points = result['weighted_points'].iloc[0]\n",
    "opp_rank = result['rank'].iloc[1]\n",
    "\n",
    "opp_points = result['weighted_points'].iloc[1]\n",
    "row['average_rank'] = (home_rank + opp_rank) / 2\n",
    "row['rank_difference'] = home_rank - opp_rank\n",
    "row['point_difference'] = home_points - opp_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   average_rank  rank_difference  point_difference  is_stake\n",
      "0          76.0            138.0           -618.28       1.0\n",
      "0.9451444141329193\n"
     ]
    }
   ],
   "source": [
    "home_win = model3.predict_proba(row)\n",
    "print(row)\n",
    "print(home_win[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "France win with a probability of 0.9451444141329193\n"
     ]
    }
   ],
   "source": [
    "if home_win[0][0]>=0.45 and home_win[0][0]<=0.55:\n",
    "    print(\"draw\")\n",
    "if home_win[0][0]>0.55:\n",
    "    print(result['country_full'].iloc[1], \"win with a probability of\",home_win[0][0])\n",
    "if home_win[0][1]>0.55:\n",
    "    print(result['country_full'].iloc[0], \" win with a probability of\",home_win[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model1.pkl']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(model3,'model1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['average_rank', 'rank_difference', 'point_difference', 'is_stake'], dtype='object')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test3.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['rank_date', 'rank', 'country_full', 'country_abrv',\n",
       "       'cur_year_avg_weighted', 'two_year_ago_weighted',\n",
       "       'three_year_ago_weighted', 'weighted_points'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rankings.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y in last_rank.country_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Afghanistan'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Afghanistan'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_rank.country_full[5622]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5622        True\n",
       "14692      False\n",
       "23762      False\n",
       "30932      False\n",
       "38802      False\n",
       "           ...  \n",
       "1788692    False\n",
       "1797762    False\n",
       "1806832    False\n",
       "1821587    False\n",
       "1830657    False\n",
       "Name: country_full, Length: 211, dtype: bool"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x == last_rank.country_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y in last_rank.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = \"afghanistan\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y == last_rank.country_full[5622]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "z= x.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z in last_rank['country_full'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5622          AFGHANISTAN\n",
       "14692             ALBANIA\n",
       "23762             ALGERIA\n",
       "30932      AMERICAN SAMOA\n",
       "38802             ANDORRA\n",
       "                ...      \n",
       "1788692           VIETNAM\n",
       "1797762             WALES\n",
       "1806832             YEMEN\n",
       "1821587            ZAMBIA\n",
       "1830657          ZIMBABWE\n",
       "Name: country_full, Length: 211, dtype: object"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_rank['country_full'].str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = 'Afghanistan'\n",
    "z = z.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AFGHANISTAN'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z in last_rank.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z in last_rank.country_full.str.upper().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
